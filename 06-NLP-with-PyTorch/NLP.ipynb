{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15de4d48-e885-4e34-bfe7-988149ff567d",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "- Networks do not understand raw text so all text has to be encoded.\n",
    "- Then it needs to be one-hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78959278-9e24-43a3-bdbe-908518d127b9",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d80803e-49ee-4d37-808a-900844185c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff4b27-b535-43f5-90cd-5f9235e3a8c4",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f5253c-d293-4e24-b565-c03fb50ff7f0",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcaf992a-97b8-4393-98d1-3dcca4b9d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/shakespeare.txt','r', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893be459-9459-40e2-9e03-47e164680c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     2\n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:  \n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy lusty days;\n",
      "  To say within thine own deep su\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c08c5-8acf-4b5d-be92-bd7ad06068e5",
   "metadata": {},
   "source": [
    "## Encoding text\n",
    "\n",
    "We will create a set of all characters, assign an id to each character, and build two dictionaries one with id > text, another with text > id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694ed8d8-bcdf-46be-a08d-cca34b4aba29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a set of all unique characters in the text\n",
    "all_characters = set(text)\n",
    "len(all_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528be15c-11c9-4c8d-88b6-0e129e647139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '<',\n",
       " 1: 'z',\n",
       " 2: 't',\n",
       " 3: 'b',\n",
       " 4: 'W',\n",
       " 5: '`',\n",
       " 6: 'e',\n",
       " 7: '(',\n",
       " 8: 'v',\n",
       " 9: 'o',\n",
       " 10: '}',\n",
       " 11: 'P',\n",
       " 12: 'n',\n",
       " 13: '2',\n",
       " 14: 'l',\n",
       " 15: 'N',\n",
       " 16: '4',\n",
       " 17: 'q',\n",
       " 18: '9',\n",
       " 19: 'k',\n",
       " 20: 'g',\n",
       " 21: 'E',\n",
       " 22: 'H',\n",
       " 23: 'F',\n",
       " 24: '1',\n",
       " 25: '6',\n",
       " 26: 'u',\n",
       " 27: 'X',\n",
       " 28: 'Q',\n",
       " 29: '0',\n",
       " 30: '>',\n",
       " 31: 'S',\n",
       " 32: '-',\n",
       " 33: 'D',\n",
       " 34: '\\n',\n",
       " 35: ';',\n",
       " 36: \"'\",\n",
       " 37: '5',\n",
       " 38: 'U',\n",
       " 39: 'V',\n",
       " 40: ' ',\n",
       " 41: 'I',\n",
       " 42: '.',\n",
       " 43: 'Y',\n",
       " 44: 'x',\n",
       " 45: ',',\n",
       " 46: 'j',\n",
       " 47: 'K',\n",
       " 48: '&',\n",
       " 49: 'C',\n",
       " 50: 'A',\n",
       " 51: 'm',\n",
       " 52: 'h',\n",
       " 53: 'O',\n",
       " 54: 'i',\n",
       " 55: 'Z',\n",
       " 56: '3',\n",
       " 57: 'M',\n",
       " 58: ':',\n",
       " 59: ')',\n",
       " 60: 'J',\n",
       " 61: 'B',\n",
       " 62: '[',\n",
       " 63: 'y',\n",
       " 64: 'r',\n",
       " 65: ']',\n",
       " 66: 'p',\n",
       " 67: '_',\n",
       " 68: 'c',\n",
       " 69: 'T',\n",
       " 70: 'a',\n",
       " 71: 'w',\n",
       " 72: 'L',\n",
       " 73: '?',\n",
       " 74: 'd',\n",
       " 75: '8',\n",
       " 76: '7',\n",
       " 77: 'G',\n",
       " 78: 'f',\n",
       " 79: '!',\n",
       " 80: 's',\n",
       " 81: '|',\n",
       " 82: 'R',\n",
       " 83: '\"'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a decoder that reads the ID and returns the character.\n",
    "# Assign an ID to each character and save it in a dictionary\n",
    "decoder = dict(enumerate(all_characters))\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88b71ac-ff0a-4431-852d-9ab7c583e014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<': 0,\n",
       " 'z': 1,\n",
       " 't': 2,\n",
       " 'b': 3,\n",
       " 'W': 4,\n",
       " '`': 5,\n",
       " 'e': 6,\n",
       " '(': 7,\n",
       " 'v': 8,\n",
       " 'o': 9,\n",
       " '}': 10,\n",
       " 'P': 11,\n",
       " 'n': 12,\n",
       " '2': 13,\n",
       " 'l': 14,\n",
       " 'N': 15,\n",
       " '4': 16,\n",
       " 'q': 17,\n",
       " '9': 18,\n",
       " 'k': 19,\n",
       " 'g': 20,\n",
       " 'E': 21,\n",
       " 'H': 22,\n",
       " 'F': 23,\n",
       " '1': 24,\n",
       " '6': 25,\n",
       " 'u': 26,\n",
       " 'X': 27,\n",
       " 'Q': 28,\n",
       " '0': 29,\n",
       " '>': 30,\n",
       " 'S': 31,\n",
       " '-': 32,\n",
       " 'D': 33,\n",
       " '\\n': 34,\n",
       " ';': 35,\n",
       " \"'\": 36,\n",
       " '5': 37,\n",
       " 'U': 38,\n",
       " 'V': 39,\n",
       " ' ': 40,\n",
       " 'I': 41,\n",
       " '.': 42,\n",
       " 'Y': 43,\n",
       " 'x': 44,\n",
       " ',': 45,\n",
       " 'j': 46,\n",
       " 'K': 47,\n",
       " '&': 48,\n",
       " 'C': 49,\n",
       " 'A': 50,\n",
       " 'm': 51,\n",
       " 'h': 52,\n",
       " 'O': 53,\n",
       " 'i': 54,\n",
       " 'Z': 55,\n",
       " '3': 56,\n",
       " 'M': 57,\n",
       " ':': 58,\n",
       " ')': 59,\n",
       " 'J': 60,\n",
       " 'B': 61,\n",
       " '[': 62,\n",
       " 'y': 63,\n",
       " 'r': 64,\n",
       " ']': 65,\n",
       " 'p': 66,\n",
       " '_': 67,\n",
       " 'c': 68,\n",
       " 'T': 69,\n",
       " 'a': 70,\n",
       " 'w': 71,\n",
       " 'L': 72,\n",
       " '?': 73,\n",
       " 'd': 74,\n",
       " '8': 75,\n",
       " '7': 76,\n",
       " 'G': 77,\n",
       " 'f': 78,\n",
       " '!': 79,\n",
       " 's': 80,\n",
       " '|': 81,\n",
       " 'R': 82,\n",
       " '\"': 83}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an encoder that reads the character and returns the ID.\n",
    "encoder = {char:ind for ind,char in decoder.items()}\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2b79e0-84e4-451b-ba68-d207398dfa72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
       "       40, 40, 40, 40, 40, 24, 34, 40, 40, 23, 64,  9, 51, 40, 78, 70, 54,\n",
       "       64,  6, 80,  2, 40, 68, 64,  6, 70,  2, 26, 64,  6, 80, 40, 71,  6,\n",
       "       40, 74,  6, 80, 54, 64,  6, 40, 54, 12, 68, 64,  6, 70, 80,  6, 45,\n",
       "       34, 40, 40, 69, 52, 70,  2, 40,  2, 52,  6, 64,  6,  3, 63, 40,  3,\n",
       "        6, 70, 26,  2, 63, 36, 80, 40, 64,  9, 80,  6, 40, 51, 54])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the text as a numpy array\n",
    "encoded_text = np.array([encoder[char] for char in text])\n",
    "encoded_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bf421-9391-4982-ab65-b3777530db83",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "\n",
    "We will be creating a one-hot encoding matrix of all characters in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "964111e5-a50c-479a-bbed-ab8b143f0092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(encoded_text, num_uni_chars):\n",
    "    '''\n",
    "    Returns a one-hot encoded matrix of shape (encoded_text.size, unique_characters)\n",
    "    Parameters\n",
    "    ----------\n",
    "    - encoded_text [np.array]: batch of encoded text\n",
    "    - num_uni_chars [int]: number of unique characters in the text\n",
    "    '''\n",
    "    \n",
    "    # Create a matrix of zeros\n",
    "    one_hot = np.zeros((encoded_text.size,num_uni_chars))\n",
    "    \n",
    "    # Convert the matrix to Float32 to ensure Torch compatibility\n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "    \n",
    "    # One-hot encode original matrix\n",
    "    one_hot[np.arange(one_hot.shape[0]),encoded_text.flatten()] = 1.0\n",
    "    \n",
    "    # Reshape to match the batch size. \n",
    "    one_hot = one_hot.reshape((*encoded_text.shape,num_uni_chars))\n",
    "    \n",
    "    return one_hot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d07108fc-0fba-417d-a9d3-837c8c90477e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "one_hot_encoder(np.array([0,2,2,3,1]),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce237b6-e749-4850-8525-e8742ef30045",
   "metadata": {},
   "source": [
    "## Training batches\n",
    "\n",
    "The training batches target data will be the data shifted by one position. Instead of providing only the next letter, the entire context will be provided. This will allow the network to learn the gramatical rules, not just the most probable letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "356a5b4f-1b81-450b-9eac-2c1b57beb6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = ['H', 'e', 'l', 'l', 'o', ' ', 't', 'h', 'e', 'r']\n",
      "y = ['e', 'l', 'l', 'o', ' ', 't', 'h', 'e', 'r', 'e']\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "t = [c for c in 'Hello there']\n",
    "print(f'X = {t[:-1]}')\n",
    "print(f'y = {t[1:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b689b2-e9bc-4fe3-9c9e-0684f18ee9bd",
   "metadata": {},
   "source": [
    "We need to create a batch generator that will reshape the data to be of shape (batches, elements per batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c639cee4-e967-4949-9209-2165e7325168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text = [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n",
      "\n",
      "Transformed to 5 batches = \n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "sample_text = np.arange(100)\n",
    "print(f'Original text = {sample_text}')\n",
    "print(f'\\nTransformed to 5 batches = \\n{sample_text.reshape(10,-1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc2729-f523-49d1-9868-f62da6338ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    '''\n",
    "    Generator object to create training batches as requested.\n",
    "    Parameters\n",
    "    ----------\n",
    "    - encoded_text [np.array]: encoded text to be batched\n",
    "    - samp_per_batch [int]: samples per batch that will be created\n",
    "    - seq_len [int]: number of characters to include in each sample\n",
    "    \n",
    "    Output\n",
    "    -------\n",
    "    X [np.array]: encoded text of length seq_len\n",
    "    y [np.array]: X shifted by one position to the right\n",
    "    '''\n",
    "    \n",
    "    # Calculate total number of characters per batch\n",
    "    chars_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    # Calculate the total number of batches that can be made\n",
    "    num_batches = int(len(encoded_text)/chars_per_batch)\n",
    "    \n",
    "    # Remove extra characters that won't fit into a batch\n",
    "    encoded_text = encoded_text[:num_batches*chars_per_batch]\n",
    "    \n",
    "    # Reshape encoded text\n",
    "    encoded_text.reshape((samp_per_batch,-1))\n",
    "    \n",
    "    # Generate sequences\n",
    "    for i in range(0,encoded_text.shape[1],seq_len):\n",
    "        \n",
    "        X = encoded_text[:,i:i+seq_len]\n",
    "        y = np.zeros_like(x)\n",
    "        \n",
    "        # [1,2,3]        \n",
    "        # [0,0,0] --> [2,3,4]\n",
    "        \n",
    "        y[:,:-1] = x[:,1:] # Insert in y the x values shifted by one place. X is one position smaller than y\n",
    "        y[:,-1] = encoded_text[:i+seq_len] # Insert the following value. This is different to i:i+seq_len as "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
